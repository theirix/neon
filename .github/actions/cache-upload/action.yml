name: "Upload cache"
description: "Custom upload action"
inputs:
  key:
    description: "Cache key"
    required: true
  path:
    description: "A directory or file to upload"
    required: true
  folder:
    description: "S3 subfolder"
    default: cache
    required: false
  override:
    description: "Allow force upload existing cache"
    default: false
    required: false

runs:
  using: "composite"
  steps:
    - name: Prepare cache
      shell: bash -euxo pipefail {0}
      env:
        SOURCE: ${{ inputs.path }}
        ARCHIVE: /tmp/uploads/${{ inputs.key }}.tar
      run: |
        ls -la
        mkdir -p $(dirname $ARCHIVE)
        
        for i in ${SOURCE} 
        do
          tar --append -f ${ARCHIVE} "$i"
        done
        
        time zstd -T0 ${ARCHIVE}

    - name: Upload cache
      shell: bash -euxo pipefail {0}
      env:
        ARCHIVE: /tmp/uploads/${{ inputs.key }}.tar.zst
        OVERRIDE: ${{ inputs.override }}
        FOLDER: ${{ inputs.folder }}
        BUCKET: neon-github-dev
      run: |
        FILENAME=$(basename $ARCHIVE)
        FILESIZE=$(du -sh ${ARCHIVE} | cut -f1)
        
        S3_KEY=$(aws s3api list-objects-v2 --bucket ${BUCKET} --prefix ${FOLDER} | jq -r '.Contents[].Key' | grep ${FILENAME} | tail -1 || true)
        if [ -z "${S3_KEY}" ]; then
          echo "uploading cache"
          time aws s3 mv --only-show-errors ${ARCHIVE} s3://${BUCKET}/${FOLDER}/${FILENAME}
          else
            if [ "${OVERRIDE}" = "true" ]; then
              echo "override existing cache"
              time aws s3 mv --only-show-errors ${ARCHIVE} s3://${BUCKET}/${FOLDER}/${FILENAME}
            else
              echo "cache exists, skipping upload"
          fi
        fi
        
        echo "${FILENAME} - ${FILESIZE}" >> ${GITHUB_STEP_SUMMARY}
